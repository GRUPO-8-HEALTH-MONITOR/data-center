# üé≤üîç Data Center
## Pipeline de gera√ß√£o e ingest√£o de sinais vitais

Projeto para gerar dados simulados de sensores por paciente (producer) e consumir esses arquivos para limpeza/entrega (consumer).

Estrutura principal
- `src/data_init.py` ‚Äî produtor: gera lotes por paciente e grava JSONs em `output/raw/`.
- `src/process_and_save.py` ‚Äî consumidor: l√™ `output/raw/`, normaliza com o "Spark", grava `output/trusted/` e insere em banco (`registro`).
- `src/classes/*` ‚Äî classes de sensores (cada `start(infos_medica, duration_minutes, interval_seconds)` retorna lista de registros).
- `src/services/connection_database.py` ‚Äî helper para conex√£o MySQL (opcional; suporta dry-run quando o conector n√£o est√° configurado).
- `databases/schema_health_data.sql` e `databases/seed_health_data.sql` ‚Äî schema e dados de exemplo (100 pacientes, sensores, mapeamentos).

Vis√£o geral do fluxo
- Producer: por padr√£o gera lotes a cada 10 segundos; cada lote cobre 10 segundos com amostras a cada 1 segundo (10 pontos por sensor). Grava arquivos at√¥micos em `raw/`.
- Consumer: verifica `raw/`, valida e normaliza os registros, salva arquivos limpos em `trusted/` e insere os registros v√°lidos no banco (somente quando houver mapeamento `paciente_sensor`).

Requisitos
- Python 3.9+ (o projeto foi testado com 3.11)
- (opcional, para inserir no MySQL) `mysql-connector-python`
- As depend√™ncias est√£o listadas em `requirements.txt`.

Setup r√°pido (Windows PowerShell)
1) Crie e ative virtualenv:
```powershell
python -m venv .\venv
.\venv\Scripts\Activate.ps1
```
2) Instale depend√™ncias:
```powershell
pip install -r requirements.txt
```
3) Configure vari√°veis de ambiente (opcional se rodar em dry-run):
```powershell
$env:DB_USER = 'seu_usuario'
$env:DB_PASSWORD = 'sua_senha'
$env:DB_HOST = 'localhost'
```

Banco de dados
- Para usar persist√™ncia no MySQL importe o schema:

  1. Crie o banco e tabelas executando `databases/schema_health_data.sql` no seu servidor MySQL.
  2. (Opcional) Popule com `databases/seed_health_data.sql`.

Como rodar
- Producer (gera lotes a cada 10s):
```powershell
.\venv\Scripts\python.exe -u src\data_init.py
```

- Consumer (roda continuamente, processa arquivos em `output/raw`):
```powershell
.\venv\Scripts\python.exe -u src\process_and_save.py
```

Arquivos de sa√≠da
- `output/raw/` ‚Äî arquivos JSON brutos por paciente (escritos at√¥micamente; extens√£o tempor√°ria `.tmp` usada durante grava√ß√£o).
- `output/trusted/` ‚Äî arquivos JSON j√° normalizados prontos para ingest√£o.

Comportamento de janelas e frequ√™ncia
- O produtor gera um lote a cada 10 segundos (par√¢metro `generation_interval_seconds` dentro de `src/data_init.py`).
- Cada sensor √© amostrado a cada 1 segundo (par√¢metro `sensor_interval_seconds`), produzindo ~10 registros por sensor por lote.

Resolu√ß√£o de problemas comuns
- PermissionError no Windows ao renomear `.tmp` -> `.json`:
  - Mensagem: `PermissionError: [WinError 5] Acesso negado`.
  - Causa: outro processo estava mantendo o arquivo destino aberto. J√° implementamos retry/backoff e grava√ß√£o at√¥mica para reduzir esse problema.

- Arquivos truncados antigos em `output/raw/`:
  - Arquivos gerados antes da corre√ß√£o at√¥mica podem estar truncados; remova ou mova os arquivos truncados para `output/raw/broken/` antes de rodar o consumer.

- Inser√ß√µes retornando 1364 / 'doesn't have a default value':
  - Veja se√ß√£o Banco de dados acima para aplicar `AUTO_INCREMENT` nas colunas `id`.

Melhorias que j√° est√£o implementadas
- Escrita at√¥mica (tmp + fsync + os.replace com retry)
- Consumer com retry na leitura JSON e movimenta√ß√£o de arquivos corrompidos para `output/raw/broken`
- Prefetch de sensores e mapeamentos no consumer para reduzir consultas por linha
